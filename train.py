import time
import torch
import os
from options.train_options import TrainOptions
from dataloaders import CreateDataLoader
from models import create_model
from utils.evaluation_metric import AverageMeter


if __name__ == '__main__':
    # 1. è§£æè®­ç»ƒå‚æ•°
    opt = TrainOptions().parse()
    # 2. åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
    data_loader = CreateDataLoader(opt)
    dataset = data_loader.load_data()
    dataset_size = len(data_loader)
    print('# The number of training images = %d' % dataset_size)

    # 3. åˆ›å»ºæ¨¡å‹
    model = create_model(opt)
    total_iters = 0  # æ€»è¿­ä»£æ¬¡æ•°åˆå§‹åŒ–

    # -------------------------- æ–­ç‚¹ç»­è®­é€»è¾‘ï¼šåŠ è½½å†å²è®­ç»ƒçŠ¶æ€ --------------------------
    start_epoch = opt.epoch_count  # é»˜è®¤ä»1å¼€å§‹è®­ç»ƒ
    if opt.continue_train:
        # å®šä¹‰æœ€æ–°æ¨¡å‹ä¿å­˜è·¯å¾„
        latest_model_path = os.path.join(opt.checkpoints_dir, opt.name, 'latest_net_Reg.pth')
        if not os.path.exists(latest_model_path):
            print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°æœ€æ–°æ¨¡å‹æ–‡ä»¶ {latest_model_path}ï¼Œå°†ä»ç¬¬1è½®å¼€å§‹è®­ç»ƒ")
        else:
            # åŠ è½½æ¨¡å‹ï¼ˆè‡ªåŠ¨é€‚é…GPU/CPUï¼‰
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            checkpoint = torch.load(latest_model_path, map_location=device)
            
            # åŠ è½½æ¨¡å‹æƒé‡å’Œä¼˜åŒ–å™¨çŠ¶æ€
            model.netReg.load_state_dict(checkpoint['model_state_dict'])
            model.optimizer_Reg.load_state_dict(checkpoint['optimizer_state_dict'])
            # è¯»å–å†å²è®­ç»ƒè½®æ¬¡å’Œæ€»è¿­ä»£æ¬¡æ•°
            start_epoch = checkpoint['epoch'] + 1
            total_iters = checkpoint['total_iters']
            
            print(f'âœ… æ–­ç‚¹ç»­è®­æˆåŠŸï¼šä»ç¬¬ {start_epoch} è½®ï¼ˆæ€»è¿­ä»£ {total_iters} æ¬¡ï¼‰å¼€å§‹è®­ç»ƒ')
    # -------------------------------------------------------------------------------------

    # 4. è®­ç»ƒå¾ªç¯ï¼šä»start_epochå¼€å§‹
    for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):
        epoch_start_time = time.time()
        iter_data_time = time.time()
        epoch_iter = 0

        # 5. å•è½®è®­ç»ƒï¼šéå†æ‰€æœ‰è®­ç»ƒæ•°æ®
        for i, data in enumerate(dataset):
            iter_start_time = time.time()
            
            # åˆå§‹åŒ–t_dataä¸º0ï¼ˆå…³é”®ä¿®å¤ï¼šé¿å…æœªå®šä¹‰ï¼‰
            t_data = 0.0  # æ·»åŠ è¿™è¡Œï¼Œç¡®ä¿å˜é‡å§‹ç»ˆå­˜åœ¨
            # æ‰“å°æ•°æ®åŠ è½½æ—¶é—´ï¼ˆæ¯print_freqæ¬¡è¿­ä»£ï¼‰
            if total_iters % opt.print_freq == 0:
                t_data = iter_start_time - iter_data_time  # ä»…æ­¤æ—¶æ›´æ–°ä¸ºå®é™…å€¼

            # æ›´æ–°è¿­ä»£æ¬¡æ•°
            total_iters += opt.batchSize
            epoch_iter += opt.batchSize

            # æ¨¡å‹å‰å‘+åå‘ä¼ æ’­
            model.set_input(data)
            model.optimize_parameters()

            # æ‰“å°è®­ç»ƒæŸå¤±
            if total_iters % opt.print_freq == 0:
                losses = model.get_current_losses()
                t_comp = (time.time() - iter_start_time) / opt.batchSize
                # ç°åœ¨t_dataä¸€å®šå·²å®šä¹‰ï¼Œä¸ä¼šæŠ¥é”™
                print(f"[Epoch {epoch}/{opt.niter+opt.niter_decay}] [Iter {epoch_iter}/{dataset_size*opt.batchSize}] "
                      f"total_loss: {losses['total']:.4f} | recon_loss: {losses['recon']:.4f} "
                      f"| smooth_loss: {losses['smooth']:.4f} | contrastive_loss: {losses['contrastive']:.4f} "
                      f"| t_comp: {t_comp:.2f}s | t_data: {t_data:.2f}s")

            # ä¿å­˜æœ€æ–°æ¨¡å‹
            if total_iters % opt.save_latest_freq == 0:
                print(f'\nğŸ“Œ ä¿å­˜æœ€æ–°æ¨¡å‹ï¼ˆepoch {epoch}ï¼Œæ€»è¿­ä»£ {total_iters} æ¬¡ï¼‰...')
                save_dir = os.path.join(opt.checkpoints_dir, opt.name)
                os.makedirs(save_dir, exist_ok=True)
                save_filename = f'iter_{total_iters}_net_Reg.pth' if opt.save_by_iter else 'latest_net_Reg.pth'
                save_path = os.path.join(save_dir, save_filename)

                torch.save(
                    {
                        'epoch': epoch,
                        'total_iters': total_iters,
                        'model_state_dict': model.netReg.state_dict(),
                        'optimizer_state_dict': model.optimizer_Reg.state_dict(),
                        'loss': losses['total']
                    },
                    save_path
                )
                print(f"âœ… æœ€æ–°æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{save_path}")

            iter_data_time = time.time()

        # 6. æŒ‰epochä¿å­˜æ¨¡å‹
        if epoch % opt.save_epoch_freq == 0:
            print(f'\nğŸ“Œ ä¿å­˜ç¬¬ {epoch} è½®æ¨¡å‹ï¼ˆæ€»è¿­ä»£ {total_iters} æ¬¡ï¼‰...')
            save_dir = os.path.join(opt.checkpoints_dir, opt.name)
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f'{epoch}_net_Reg.pth')

            torch.save(
                {
                    'epoch': epoch,
                    'total_iters': total_iters,
                    'model_state_dict': model.netReg.state_dict(),
                    'optimizer_state_dict': model.optimizer_Reg.state_dict(),
                    'loss': model.get_current_losses()['total']
                },
                save_path
            )
            print(f"âœ… ç¬¬ {epoch} è½®æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{save_path}")

        # 7. æ‰“å°å•è½®è®­ç»ƒæ€»è€—æ—¶
        epoch_total_time = time.time() - epoch_start_time
        print(f'\nğŸ”š ç¬¬ {epoch} è½®è®­ç»ƒç»“æŸ | æ€»è€—æ—¶ï¼š{epoch_total_time:.0f} ç§’\n')

        # 8. æ›´æ–°å­¦ä¹ ç‡
        model.update_learning_rate()

